;; SPDX-License-Identifier: PMPL-1.0-or-later
;; META.scm - Project metadata and architectural decisions for Axiom.jl

(define project-meta
  `((version . "1.0.0")
    (architecture-decisions
      ((adr-001 . ((title . "Multi-backend architecture via AbstractBackend dispatch")
                   (status . "accepted")
                   (context . "ML ops need to run on CPU, GPU, and accelerators with different performance profiles")
                   (decision . "Define AbstractBackend type hierarchy with JuliaBackend as default, RustBackend/ZigBackend/CUDABackend/ROCmBackend/MetalBackend as alternatives. Global backend switchable via set_backend!. Julia backend is always the reference implementation.")
                   (consequences . "Each backend must implement the full ops interface. Fallback to Julia when native backend unavailable.")))
       (adr-002 . ((title . "Rust for parallel compute, Zig for SIMD kernels")
                   (status . "accepted")
                   (context . "Need high-performance native backends. Rust excels at parallelism (Rayon), Zig at low-level SIMD.")
                   (decision . "Rust backend for ops benefiting from parallelism (matmul, conv). Zig backend for element-wise SIMD ops (activations, normalization). Both expose C ABI via FFI.")
                   (consequences . "Two native codebases to maintain. Julia ccall bindings for both. Users must compile .so/.dylib from source.")))
       (adr-003 . ((title . "GPU backends as Julia package extensions")
                   (status . "accepted")
                   (context . "GPU packages (CUDA.jl, AMDGPU.jl, Metal.jl) are heavy dependencies that most users don't need")
                   (decision . "Use Julia's package extension mechanism. GPU backends defined in ext/ and loaded conditionally when user imports CUDA/AMDGPU/Metal.")
                   (consequences . "Clean dependency tree. GPU ops only available when user explicitly loads GPU package.")))
       (adr-004 . ((title . "SMT-based formal verification via @prove macro")
                   (status . "accepted-but-disabled")
                   (context . "Core value proposition is provably correct ML. Need formal property verification.")
                   (decision . "Bundled SMTLib.jl package provides solver interface. @prove macro translates Julia properties to SMT-LIB2 and checks against Z3/CVC5/Yices/MathSAT.")
                   (consequences . "@prove currently disabled due to weak dependency import ordering. Needs refactor to package extension pattern.")))
       (adr-005 . ((title . "Proof certificates with SHA256 integrity")
                   (status . "accepted")
                   (context . "Verification results must be serializable and verifiable by third parties")
                   (decision . "ProofCertificate struct with SHA256 hash. Serialize/deserialize to JSON. Export stubs to Lean 4, Coq, Isabelle/HOL for external verification.")
                   (consequences . "Current export generates sorry/Admitted placeholders. Real proof translation is future work.")))
       (adr-006 . ((title . "PyTorch interoperability via PyCall extension")
                   (status . "accepted")
                   (context . "Most existing ML models are in PyTorch. Need import path for verification.")
                   (decision . "AxiomPyTorchExt provides bidirectional conversion (Dense, Conv2d, BatchNorm, activations). State dict parsing for weight transfer.")
                   (consequences . "Depends on PyCall.jl and user's Python/PyTorch installation. HuggingFace model-specific converters still needed.")))))
    (development-practices
      ((code-style . "julian")
       (security . "openssf-scorecard")
       (versioning . "semver")
       (documentation . "asciidoc")
       (branching . "trunk-based")
       (testing . "julia-test-stdlib")
       (license . "PMPL-1.0-or-later")))
    (design-rationale
      ((why-julia . "First-class support for scientific computing, multiple dispatch enables clean backend abstraction, metaprogramming for @axiom/@ensure/@prove macros, strong numerics ecosystem")
       (why-not-flux . "Flux.jl is excellent but doesn't provide formal verification. Axiom.jl's value is the proof layer, not the tensor ops.")
       (why-smt . "SMT solvers provide decidable fragments of first-order logic. Properties like 'softmax sums to 1' and 'relu output >= 0' are directly expressible in SMT-LIB2.")))))
